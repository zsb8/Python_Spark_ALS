# Python_Spark_ALS
Use ALS on Spark to create a recommend engine

Type this command on Linux, use spark-submit to run the code.
```
spark-submit --master spark://node1:7077  /tmp/pycharm_project_485/01_RDD/test.py
```
Got the result:    
![image](https://user-images.githubusercontent.com/75282285/191273892-5f40e7a8-d048-47f2-917c-a090838356e7.png)

You can find the Running Applications on Spark http://node1:8080/     
![image](https://user-images.githubusercontent.com/75282285/191274075-83e1e385-da5b-40b2-b837-5c7579ca71d0.png)

You can see it used 3 machine to currency calculate. 
![image](https://user-images.githubusercontent.com/75282285/191274224-967a9429-09bf-4e99-8ada-0b8040f76829.png)
